University: [ITMO University](https://itmo.ru/ru/)
Faculty: [FITM](https://ftmi.itmo.ru)
Course: [Cloud platforms as the basis of technology entrepreneurship](https://) ADD link
Year: 2025/2026
Group: U4225
Author: Budaev Alexandr Sayanovich
Lab: Lab4
Date of create: 25.11.2025
Date of finished: 25.11.2025

# Лабораторная работа №4  
## Разработка инфраструктуры MVP AI-приложения

### **Цель работы**
Изучить подход к проектированию инфраструктуры AI-приложений, разработать архитектуру для трёх стадий развития продукта (MVP, тестирование партнёров, продовая версия), оценить стоимость использования облачных ресурсов и обосновать выбор технологий.

---

## **Описание приложения**
Рассматривается простое AI-приложение — чат-бот/LLM-ассистент, отвечающий на пользовательские запросы. Приложение включает backend-часть, хранилище данных и сервис для выполнения AI-инференса.

---

## **Этап 1 — MVP архитектура**

Минимально необходимая инфраструктура:

- **Cloud Run** — backend API, принимающий HTTP-запросы от пользователей и инкапсулирующий логику приложения (валидация запросов, формирование промптов для модели, обработка ответов).
- **AI-модель** (через Vertex AI API или внешний API) — сама модель не разворачивается “у нас”, а вызывается как облачный сервис по HTTP/HTTPS. Это снижает входной порог: можно не заниматься обучением и развёртыванием собственной модели.
- **Cloud Storage / Firestore** — хранилище для истории диалогов и минимального пользовательского профиля (например, ID пользователя, время последнего запроса, контекст). На MVP этого достаточно, сложные схемы БД не нужны.
- **Cloud Logging** — базовая система логирования для отладки: просмотр ошибок, задержек ответа, частоты запросов.

**Почему такая архитектура на MVP:**

- Используется **полностью serverless-подход**: Cloud Run автоматически поднимает контейнер только при запросах и масштабируется до нуля. Это позволяет не платить за “простаивающий” сервер.
- Backend отделён от модели: если в будущем потребуется сменить поставщика AI (например, с внешнего API на Vertex AI), это делается на уровне backend-кода без полной перестройки инфраструктуры.
- Хранилище максимально простое: вместо сразу сложной схемы с несколькими базами достаточно одного Cloud Storage/Firestore, чтобы сохранить минимум данных для улучшения UX.
- Логирование подключено с первого дня, но без сложной аналитики — на MVP важнее иметь возможность вообще увидеть ошибки и трейс, а не строить дашборды.

Таким образом, схема отражает главный приоритет MVP: **запуститься быстро и дёшево**, не вкладываясь в тяжёлую инфраструктуру и не беря на себя ответственность за обслуживание сложных ML-сервисов.

![img.png](img.png)
---

## **Этап 2 — Архитектура для тестирования партнёрами**

Расширенная инфраструктура:

- **Отдельный backend (staging) для партнёров** — создаётся отдельный сервис/деплой Cloud Run, на который ходят только партнёры. Это позволяет:
  - тестировать новые фичи, не ломая основной MVP,
  - собирать отдельную статистику по партнёрскому трафику,
  - при необходимости ограничивать доступ по токенам/IP.
- **Autoscaling для Cloud Run** — включается более агрессивное масштабирование (больше максимальное количество инстансов), т.к. партнёры уже генерируют нагрузку, им нельзя показывать долгие задержки и ошибки по “ресурсам”.
- **Отдельный bucket для логов и аналитики** — выделяется хранилище под логи запросов, ответы модели, техническую телеметрию. Это нужно, чтобы:
  - анализировать поведение пользователей/партнёров,
  - строить простую аналитику (например, частота запросов, типы задач),
  - не смешивать “боевые” и тестовые данные.
- **Контроль доступа и IAM-роли** — на этом этапе появляются первые требования к разграничению доступа: разработчики, аналитики, партнёры, администраторы получают разные права на чтение/запись.
- **Версионность моделей / конфигураций backend-сервисов** — появляется необходимость экспериментировать с промптами, параметрами генерации, выборами моделей. Логично хранить и применять конфигурации по версиям (на уровне переменных окружения/конфигов).

**Почему архитектура усложняется именно так:**

- Появление партнёров означает, что приложение начинает использоваться в более “реальных” условиях. Нельзя рисковать единственным инстансом backend’а и отсутствием масштабирования.
- Разделение сред (MVP/боевое и партнёрское/staging) снижает риск: эксперимент можно “сломать” без влияния на основную версию.
- Логи и аналитика превращаются из “отладочной опции” в инструмент принятия решений: какие фичи важны, где узкие места в производительности, какие сценарии использования реальные, а не гипотетические.
- IAM и права доступа — это задел на прод: проще внедрить дисциплину доступа на раннем этапе, чем потом “расчищать завалы”.

Таким образом, схема второго этапа отражает переход от “одиночного прототипа” к **контролируемому тестированию с внешними пользователями**, где важны наблюдаемость, управляемость и первые элементы безопасности.
![img_1.png](img_1.png)
---

## **Этап 3 — Продовая архитектура**

Полноценная продуктивная инфраструктура:

- **Vertex AI Endpoint или GPU-VM** — выделенный сервис для инференса:
  - даёт предсказуемое время отклика,
  - умеет масштабироваться по запросам,
  - позволяет управлять версиями модели (катить обновления поэтапно).
- **Load Balancer** — единая точка входа для внешнего трафика. Балансировщик:
  - распределяет запросы между несколькими backend-инстансами,
  - позволяет постепенно выкатывать новые версии (canary/blue-green),
  - обеспечивает базовые средства безопасности (HTTPS, сертификаты).
- **VPC (виртуальная частная сеть)** — backend, инференс и базы данных живут внутри приватной сети:
  - закрыт прямой доступ к сервисам извне,
  - доступ идёт только через балансировщик или строго настроенные правила.
- **Cloud Monitoring + Alerts** — система наблюдения за продом:
  - отслеживаются задержки, коды ошибок, насыщение CPU/памяти,
  - настраиваются алерты (например, при росте 5xx-ошибок или увеличении latency).
- **Разделённые buckets: data / logs / backups**:
  - **data** — пользовательские данные и контекст (с отдельной политикой доступа),
  - **logs** — технические логи (могут храниться ограниченное время),
  - **backups** — резервные копии критичных данных и конфигураций.
- **Autoscaling & Failover**:
  - backend-сервисы автоматически масштабируются по нагрузке (кол-во запросов/сек),
  - предусмотрен сценарий отказа одного из компонентов (например, замена зоны/региона, fallback-модель).

**Почему продовая архитектура именно такая:**

- В проде основной приоритет — **надёжность и предсказуемость**.  
  Один инстанс или одна зона — это уже риск. Поэтому добавляются балансировка, отказоустойчивость и разделение ответственности между сервисами.
- Отдельный inference-endpoint (Vertex AI/GPU-VM) логически выносит “тяжёлую ML-нагрузку”:
  - backend остаётся лёгким (валидация, оркестрация, авторизация),
  - команда, занимающаяся моделью, может обновлять её независимо от фронтов и API.
- VPC и явное разделение хранилищ — это **про безопасность и соответствие требованиям** (в дальнейшем — GDPR, корпоративные политики и т.д.).
- Наблюдаемость (Monitoring + Alerts) — обязательное требование: без неё нельзя гарантировать SLA и быстро реагировать на падения или деградацию.
- Отдельные buckets для данных, логов и бэкапов позволяют:
  - по-разному настраивать политики хранения (например, логи — 30 дней, бэкапы — 1 год),
  - отделить чувствительные данные от “технического мусора”.

Таким образом, продовая архитектура показывает переход от “рабочего прототипа” к **инженерно зрелому сервису**, который можно масштабировать, сопровождать и поддерживать в долгую.
![img_2.png](img_2.png)

## **Обоснование выбора ресурсов**

- **MVP:** выбраны Cloud Run + внешняя/managed AI-модель + простое хранилище, так как задача — проверить гипотезу продукта с минимальными затратами времени и денег. Нет смысла в этом состоянии поднимать собственные кластеры, VPC и сложный мониторинг.
- **Тестирование партнёрами:** добавление отдельной среды (staging), autoscaling и логирования/аналитики оправдано тем, что появляется внешняя нагрузка и реальные пользователи. Нужно отделить эксперименты от базового функционала, накопить данные об использовании и начать управлять доступом.
- **Прод:** архитектура усложняется не “ради красоты”, а ради требований к системе: доступность, безопасность, масштабируемость, наблюдаемость. Появляются балансировщик, dedicated inference-сервис, VPC, несколько хранилищ и алерты. Это позволяет выдерживать рост нагрузки и поддерживать качество сервиса без ручного “тушения пожаров”.

В совокупности эти три схемы показывают эволюцию одного и того же AI-приложения от простого прототипа до продовой системы, где каждая новая “ступень” добавляет не абстрактные компоненты, а ответы на конкретные инженерные и бизнес-задачи.
---

## **Экономическая модель (оценка затрат)**

### **MVP (~5–10$/мес)**
- Cloud Run (минимальная загрузка): 0–5$  
- Cloud Storage: <1$  
- Logs/Monitoring: <1$  

Итого: **~5–10$**

### **Тестирование (~30–60$/мес)**
- Два Cloud Run инстанса + autoscaling: 10–20$  
- Отдельные buckets: <1$  
- Небольшая VM для тестового инференса: 20–40$  

Итого: **~30–60$**

### **Прод (~200–400$/мес)**
- Vertex AI Endpoint / GPU VM: 150–300$  
- Load Balancer: 15–20$  
- Monitoring + Logging: 10–20$  
- Storage: 1–5$  

Итого: **~200–400$**

---

## **Обоснование выбора ресурсов**
- **Serverless-подход на MVP** — минимальные затраты и отсутствие DevOps.  
- **Авто-масштабирование на стадии тестирования** — партнёры могут давать всплески нагрузки.  
- **Отдельный inference-endpoint на проде** — стабильность, скорость и SLA.  
- **Разделение хранилищ** — безопасность и структурированность данных.  
- **Мониторинг и балансировка** — требование к стабильности продового продукта.  

---

## **Вывод**
Разработана инфраструктура AI-приложения для трёх стадий развития — от минимального MVP до продовой версии. Построены архитектуры, сформирована экономическая модель и выполнено обоснование выбора облачных сервисов.
